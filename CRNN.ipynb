{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omega/anaconda3/lib/python3.8/site-packages/lazy_loader/__init__.py:185: RuntimeWarning: subpackages can technically be lazily loaded, but it causes the package to be eagerly loaded even if it is already lazily loaded.So, you probably shouldn't use subpackages with this lazy feature.\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "/home/omega/anaconda3/lib/python3.8/site-packages/lazy_loader/__init__.py:185: RuntimeWarning: subpackages can technically be lazily loaded, but it causes the package to be eagerly loaded even if it is already lazily loaded.So, you probably shouldn't use subpackages with this lazy feature.\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psutil\n",
    "import random\n",
    "import soundfile as sf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, GRU, Dense, Reshape, Flatten\n",
    "from keras.models import Model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from pydub import AudioSegment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- main -------------------------------------------------------------------------\n",
    "#!mkdir temp\n",
    "\n",
    "# --> Load Files\n",
    "def load(paths):\n",
    "    if type(paths) == str : return np.load(paths)\n",
    "    values = []\n",
    "    \n",
    "    for path in paths:\n",
    "        var = np.load(path)\n",
    "        values.append(var)\n",
    "    \n",
    "    return np.array(values)\n",
    "\n",
    "# --> Save DataFrames\n",
    "def save_df(file, name):\n",
    "    newData_path = name\n",
    "    file.to_csv(f'{newData_path}.csv', index=False)  # Save as CSV file\n",
    "    \n",
    "# ----- Tools -------------------------------------------------------------------------\n",
    "\n",
    "# --> check a varible size in mb\n",
    "def tool_var_size(var):\n",
    "    size_in_bytes = sys.getsizeof(var)\n",
    "    size_in_mb = size_in_bytes / (1024 * 1024)\n",
    "    print(f\"The size is {size_in_mb:.2f} MB.\")\n",
    "\n",
    "# --> check RAM size\n",
    "def tool_ram_size():    \n",
    "    vm_stats = psutil.virtual_memory()\n",
    "    available_str = psutil._common.bytes2human(vm_stats.available)\n",
    "    \n",
    "    print(\"Available memory: {}\".format(available_str))\n",
    "    \n",
    "# ----- Audio -------------------------------------------------------------------------\n",
    "\n",
    "# --> play [spectrogram]\n",
    "def audio_play_spec(spec, name='spec_to_audio', target_dbfs= -24):    \n",
    "    audio = librosa.istft(spec)\n",
    "  \n",
    "    newData_path = os.path.join('temp', f'{name}.wav')\n",
    "\n",
    "    sf.write(newData_path, audio, 22050) # to convert it to AudioSegment type\n",
    "    audio = AudioSegment.from_file(newData_path)\n",
    "    \n",
    "    current_dbfs = audio.dBFS\n",
    "    gain_needed = target_dbfs - current_dbfs\n",
    "    audio = audio + gain_needed\n",
    "    return audio\n",
    "\n",
    "# ----- Spectogram -------------------------------------------------------------------------\n",
    "\n",
    "# --> visualization  \n",
    "def spec_visualize(spec):\n",
    "    librosa.display.specshow((spec), sr=22050, x_axis='time', y_axis='log')\n",
    "\n",
    "# --> Applay mask on Spectrogram\n",
    "def spec_applay_mask(spec_path, mask_path):\n",
    "    \n",
    "    spec = np.load(spec_path) if isinstance(spec_path, str) else spec_path\n",
    "    mask = np.load(mask_path) if isinstance(mask_path, str) else mask_path        \n",
    "    \n",
    "    masked_spectrogram = spec * mask   \n",
    "    return masked_spectrogram\n",
    "\n",
    "# ----- Mask -------------------------------------------------------------------------\n",
    "\n",
    "# convert vector to masks\n",
    "def mask_vector_resahpe(vector, num_frequency_bins = 1025):\n",
    "    masks = vector.reshape(num_frequency_bins,-1)\n",
    "    \n",
    "    coulmns = int(masks.shape[1]/3)\n",
    "\n",
    "    mask_1 = masks[:, :coulmns]\n",
    "    mask_2 = masks[:, coulmns:coulmns*2]\n",
    "    mask_3 = masks[:, coulmns*2:]\n",
    "    \n",
    "    return mask_1, mask_2, mask_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Divider -------------------------------------------------------------------------\n",
    "class Divider():\n",
    "    def __init__(self, dataFrame, num_groups):  \n",
    "        self.df = dataFrame\n",
    "        self.size = num_groups\n",
    "        self.data = []\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def divide(self):\n",
    "        shuffled_df = self.df.sample(frac=1)\n",
    "        \n",
    "        s = 0\n",
    "        e = self.size\n",
    "\n",
    "        while e <= len(self.df):\n",
    "            self.data.append(self.df[s:e])\n",
    "           \n",
    "            s = e\n",
    "            e += self.size\n",
    "            \n",
    "        return self.data\n",
    "\n",
    "# ----- Batch -------------------------------------------------------------------------\n",
    "class Batch:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def get_items(self):\n",
    "        \n",
    "        spec = torch.from_numpy(load(self.data['spectrogram']).real)\n",
    "        vec = torch.from_numpy(load(self.data['vector']))\n",
    "        \n",
    "        spec = torch.unsqueeze(spec, dim=1)\n",
    "        return spec, vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- CNN -------------------------------------------------------------------------\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()        \n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=(3, 3), padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=(3, 3), padding=1)\n",
    "       \n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # [Batch, Channels, Height, Width]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# ----- RNN -------------------------------------------------------------------------\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size, 128)\n",
    "        self.lstm2 = nn.LSTM(128, 256)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #[Batch, TimeSteps, Features]\n",
    "        x, _ = self.lstm1(x)\n",
    "        x  = self.relu(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        \n",
    "        return x  \n",
    "\n",
    "    \n",
    "# ----- Combined Model -------------------------------------------------------------------------\n",
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, cnn_size):\n",
    "        super(CombinedModel, self).__init__()        \n",
    "        self.cnn = CNN()\n",
    "        self.rnn = RNN(cnn_size)\n",
    "        \n",
    "        self.fc1 = nn.Linear(256, 512)   \n",
    "        self.fc2 = nn.Linear(512, 267525)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        cnn_output = self.cnn(x)\n",
    "        rnn_output = self.rnn(cnn_output) \n",
    "        \n",
    "        x = self.relu(rnn_output)\n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:31<09:54, 31.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Average Loss: 0.6158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 2/20 [01:00<09:03, 30.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Average Loss: 0.1897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 3/20 [01:29<08:25, 29.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Average Loss: 0.1417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 4/20 [01:59<07:53, 29.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Average Loss: 0.1152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 5/20 [02:28<07:21, 29.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Average Loss: 0.1071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 6/20 [02:57<06:52, 29.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Average Loss: 0.1027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 7/20 [03:27<06:21, 29.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Average Loss: 0.1003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 8/20 [03:56<05:52, 29.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Average Loss: 0.0987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 8/20 [04:25<06:38, 33.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Average Loss: 0.0983 || Over Fitting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "###### ----- Read DataFram -------------------------------------------------------------------------\n",
    "length = 160\n",
    "\n",
    "df = pd.read_csv('Final_dataSet.csv')\n",
    "df = df[:length]\n",
    "df = df[['spectrogram', 'vector']]\n",
    "\n",
    "# ----- Split Data -------------------------------------------------------------------------\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.1)\n",
    "\n",
    "# ----- HyperParameters -------------------------------------------------------------------------\n",
    "\n",
    "lr = 0.001\n",
    "num_epochs = 20\n",
    "\n",
    "loss_values = []\n",
    "average_loss = 0\n",
    "\n",
    "# ----- Initialize Model -------------------------------------------------------------------------\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "model = CombinedModel(344064).to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr =lr)\n",
    "\n",
    "# ----- Start Training  -------------------------------------------------------------------------\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    total_loss = 0\n",
    "    \n",
    "    batch_size = 16\n",
    "    Batchs = Divider(train, batch_size ).divide()\n",
    "    \n",
    "# ===== Read Batch =================================================================================\n",
    "\n",
    "    for batch in Batchs:        \n",
    "            spec, vector = Batch(batch).get_items()\n",
    "            \n",
    "            spec = spec.to(device)\n",
    "            vector = vector.to(device).float()\n",
    "            \n",
    "# ===== Training =================================================================================    \n",
    "\n",
    "            outputs = model(spec).float()\n",
    "\n",
    "            loss = criterion(outputs, vector)\n",
    "            total_loss += loss.item()\n",
    "            loss_values.append(loss.item())\n",
    "                        \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "# ===== Print Results =================================================================================\n",
    "\n",
    "    if int(average_loss*1000) == int((total_loss / len(Batchs)  )*1000) : \n",
    "        average_loss = total_loss / len(Batchs)\n",
    "        print(f\"Epoch {epoch+1}, Average Loss: {average_loss:.4f} || Over Fitting\")\n",
    "        num_epochs = epoch + 1\n",
    "        break\n",
    "        \n",
    "    average_loss = total_loss / len(Batchs) \n",
    "    print(f\"Epoch {epoch+1}, Average Loss: {average_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = 0\n",
    "def calculate_accuracy(model, spec, vec= None):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        spec = spec.reshape(1,1,1025,87)\n",
    "        inputs = torch.tensor(spec).real \n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        outputs = torch.round(outputs).T.cpu()\n",
    "        return outputs\n",
    "\n",
    "        if type(vec) == None : return outputs\n",
    "\n",
    "        ground_truth = vec\n",
    "        accuracy = accuracy_score(ground_truth, outputs)*100\n",
    "        \n",
    "        print(f\"Accuracy is {accuracy:.2f} %\")\n",
    "    return accuracy\n",
    "\n",
    "X, y = df['spectrogram'], df['vector']\n",
    "spec = load(X[5])\n",
    "vec = load(y[5])\n",
    "\n",
    "mask = calculate_accuracy(model.cpu(), spec, vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "mask = mask.numpy()\n",
    "mask = np.array(mask, dtype=np.int32)\n",
    "mask = mask.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "m1, m2, m3 = mask_vector_resahpe(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                    <audio controls>\n",
       "                        <source src=\"data:audio/mpeg;base64,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\" type=\"audio/mpeg\"/>\n",
       "                        Your browser does not support the audio element.\n",
       "                    </audio>\n",
       "                  "
      ],
      "text/plain": [
       "<pydub.audio_segment.AudioSegment at 0x7f8983584ca0>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_play_spec(spec_applay_mask(m3,spec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trial</th>\n",
       "      <th>Length</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>droupOut, lr,</td>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>180</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.109534</td>\n",
       "      <td>0.968209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lr</td>\n",
       "      <td>2000</td>\n",
       "      <td>5</td>\n",
       "      <td>180</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.098949</td>\n",
       "      <td>0.969879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fault</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>180</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.396991</td>\n",
       "      <td>0.969285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Create Batch Class</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.061671</td>\n",
       "      <td>96.967386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Clean Code</td>\n",
       "      <td>1600</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.006418</td>\n",
       "      <td>96.999159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Big Length</td>\n",
       "      <td>10000</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>96.998785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Test</td>\n",
       "      <td>3200</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.006392</td>\n",
       "      <td>96.997664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Added The Bach Norm</td>\n",
       "      <td>3200</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>96.999159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Testing epochs_1</td>\n",
       "      <td>1600</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.008355</td>\n",
       "      <td>96.999159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Testing epochs_2</td>\n",
       "      <td>1600</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.006348</td>\n",
       "      <td>96.999159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Testing epochs_3</td>\n",
       "      <td>1600</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.013162</td>\n",
       "      <td>96.999159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4/10 bid</td>\n",
       "      <td>1600</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.006525</td>\n",
       "      <td>96.999159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Standard 4/10</td>\n",
       "      <td>1600</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.012501</td>\n",
       "      <td>96.999159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>simple nn</td>\n",
       "      <td>160</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.036611</td>\n",
       "      <td>97.001028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>simple nn | 4/10</td>\n",
       "      <td>160</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.012619</td>\n",
       "      <td>96.999533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>simple nn | 2/10</td>\n",
       "      <td>160</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.086525</td>\n",
       "      <td>52.244463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>simple nn</td>\n",
       "      <td>160</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.042900</td>\n",
       "      <td>96.789459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>simple</td>\n",
       "      <td>160</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.019003</td>\n",
       "      <td>97.001028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>simple + batch + drop</td>\n",
       "      <td>160</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.015320</td>\n",
       "      <td>97.000654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>simple + batch + 2drop</td>\n",
       "      <td>160</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.026136</td>\n",
       "      <td>97.000280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>simple + batch</td>\n",
       "      <td>160</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.021203</td>\n",
       "      <td>97.000654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>simple + batch</td>\n",
       "      <td>160</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.025939</td>\n",
       "      <td>97.000654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>simple + batch</td>\n",
       "      <td>160</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.021048</td>\n",
       "      <td>97.001028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>simple + batch</td>\n",
       "      <td>160</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.012305</td>\n",
       "      <td>96.999159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>simple + batch</td>\n",
       "      <td>160</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.012618</td>\n",
       "      <td>97.002523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Change the Loss</td>\n",
       "      <td>160</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.062516</td>\n",
       "      <td>50.041678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>lstm 256</td>\n",
       "      <td>160</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.006632</td>\n",
       "      <td>96.833941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>lstm 256</td>\n",
       "      <td>1600</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.003174</td>\n",
       "      <td>96.564433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>lstm 256</td>\n",
       "      <td>160</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.010939</td>\n",
       "      <td>96.419400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>lstm 256</td>\n",
       "      <td>160</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.003254</td>\n",
       "      <td>96.951313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>lstm 256</td>\n",
       "      <td>160</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.001894</td>\n",
       "      <td>96.999159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>lstm 256</td>\n",
       "      <td>160</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.030571</td>\n",
       "      <td>96.999159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>lstm 256</td>\n",
       "      <td>160</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.102921</td>\n",
       "      <td>96.999159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>lstm 256</td>\n",
       "      <td>160</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.099042</td>\n",
       "      <td>96.963648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>lstm 256</td>\n",
       "      <td>160</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.106247</td>\n",
       "      <td>96.986450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>lstm 256</td>\n",
       "      <td>160</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.098439</td>\n",
       "      <td>96.972246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>lstm 256</td>\n",
       "      <td>160</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.275469</td>\n",
       "      <td>96.996916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>lstm 256</td>\n",
       "      <td>160</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.242906</td>\n",
       "      <td>96.995421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>lstm 256</td>\n",
       "      <td>160</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.099311</td>\n",
       "      <td>96.995047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>lstm 256</td>\n",
       "      <td>160</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.099097</td>\n",
       "      <td>96.997664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>lstm 256</td>\n",
       "      <td>160</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.098323</td>\n",
       "      <td>96.997290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>lstm 256</td>\n",
       "      <td>160</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.098323</td>\n",
       "      <td>96.997290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Trial  Length  Epochs  Batch Size  Learning Rate  \\\n",
       "0            droupOut, lr,    2000       3         180        0.01000   \n",
       "1                       lr    2000       5         180        0.00100   \n",
       "2                    Fault    2000       4         180        0.00100   \n",
       "3       Create Batch Class     100       2           7        0.00100   \n",
       "4               Clean Code    1600       4          16        0.00100   \n",
       "5               Big Length   10000       6          24        0.00100   \n",
       "6                     Test    3200       6          16        0.00100   \n",
       "7      Added The Bach Norm    3200       6          16        0.00100   \n",
       "8         Testing epochs_1    1600       6          16        0.00100   \n",
       "9         Testing epochs_2    1600       6          24        0.00100   \n",
       "10        Testing epochs_3    1600       5           8        0.00100   \n",
       "11               4/10 bid     1600       5          16        0.00100   \n",
       "12          Standard 4/10     1600       4           8        0.00100   \n",
       "13               simple nn     160      10           8        0.00100   \n",
       "14        simple nn | 4/10     160       5           8        0.01000   \n",
       "15        simple nn | 2/10     160       2           8        0.00001   \n",
       "16               simple nn     160      10           8        0.00010   \n",
       "17                  simple     160      18           8        0.00100   \n",
       "18   simple + batch + drop     160      11           8        0.00100   \n",
       "19  simple + batch + 2drop     160      13           8        0.00100   \n",
       "20          simple + batch     160      20           8        0.00100   \n",
       "21          simple + batch     160      20           8        0.00100   \n",
       "22          simple + batch     160      16           8        0.00100   \n",
       "23          simple + batch     160       4           8        0.00100   \n",
       "24          simple + batch     160       4           8        0.00100   \n",
       "25         Change the Loss     160       2           8        0.00100   \n",
       "26                lstm 256     160       2           8        0.00100   \n",
       "27                lstm 256    1600       1          16        0.00100   \n",
       "28                lstm 256     160       2           4        0.01000   \n",
       "29                lstm 256     160       2          16        0.01000   \n",
       "30                lstm 256     160       2          16        0.01000   \n",
       "31                lstm 256     160       2          16        0.00100   \n",
       "32                lstm 256     160       2          16        0.00100   \n",
       "33                lstm 256     160       8          16        0.10000   \n",
       "34                lstm 256     160       3          16        0.10000   \n",
       "35                lstm 256     160       8          16        0.10000   \n",
       "36                lstm 256     160       8          16        0.00100   \n",
       "37                lstm 256     160      20          16        0.00100   \n",
       "38                lstm 256     160       8          16        0.00100   \n",
       "39                lstm 256     160      10          16        0.00100   \n",
       "40                lstm 256     160       9          16        0.00100   \n",
       "41                lstm 256     160       9          16        0.00100   \n",
       "\n",
       "        Loss   Accuracy  \n",
       "0   0.109534   0.968209  \n",
       "1   0.098949   0.969879  \n",
       "2   0.396991   0.969285  \n",
       "3   0.061671  96.967386  \n",
       "4   0.006418  96.999159  \n",
       "5   0.004131  96.998785  \n",
       "6   0.006392  96.997664  \n",
       "7   0.007117  96.999159  \n",
       "8   0.008355  96.999159  \n",
       "9   0.006348  96.999159  \n",
       "10  0.013162  96.999159  \n",
       "11  0.006525  96.999159  \n",
       "12  0.012501  96.999159  \n",
       "13  0.036611  97.001028  \n",
       "14  0.012619  96.999533  \n",
       "15  0.086525  52.244463  \n",
       "16  0.042900  96.789459  \n",
       "17  0.019003  97.001028  \n",
       "18  0.015320  97.000654  \n",
       "19  0.026136  97.000280  \n",
       "20  0.021203  97.000654  \n",
       "21  0.025939  97.000654  \n",
       "22  0.021048  97.001028  \n",
       "23  0.012305  96.999159  \n",
       "24  0.012618  97.002523  \n",
       "25  0.062516  50.041678  \n",
       "26  0.006632  96.833941  \n",
       "27  0.003174  96.564433  \n",
       "28  0.010939  96.419400  \n",
       "29  0.003254  96.951313  \n",
       "30  0.001894  96.999159  \n",
       "31  0.030571  96.999159  \n",
       "32  0.102921  96.999159  \n",
       "33  0.099042  96.963648  \n",
       "34  0.106247  96.986450  \n",
       "35  0.098439  96.972246  \n",
       "36  0.275469  96.996916  \n",
       "37  0.242906  96.995421  \n",
       "38  0.099311  96.995047  \n",
       "39  0.099097  96.997664  \n",
       "40  0.098323  96.997290  \n",
       "41  0.098323  96.997290  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib' has no attribute 'pyplot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# close triggers gc.collect, which can be slow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclose\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mGcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_fig_managers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'all'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/matplotlib/_api/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mprops\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m    227\u001b[0m             f\"module {cls.__module__!r} has no attribute {name!r}\")\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'matplotlib' has no attribute 'pyplot'"
     ]
    }
   ],
   "source": [
    "msg = 'lstm 256'\n",
    "prog = pd.read_csv('progress.csv')\n",
    "row = {\n",
    "    'Trial': [msg],\n",
    "    'Length': [length],\n",
    "    'Epochs': [num_epochs],\n",
    "    'Batch Size': [batch_size],\n",
    "    'Learning Rate': [lr],\n",
    "    'Loss': [average_loss],\n",
    "    'Accuracy': [test]\n",
    "}\n",
    "\n",
    "prog = prog.append(pd.DataFrame(row), ignore_index=True)\n",
    "prog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df(prog, 'progress')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
