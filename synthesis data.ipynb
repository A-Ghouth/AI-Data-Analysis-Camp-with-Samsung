{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install soundfile seaborn psutil pydub librosa  pydub  tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omega/.local/lib/python3.10/site-packages/lazy_loader/__init__.py:185: RuntimeWarning: subpackages can technically be lazily loaded, but it causes the package to be eagerly loaded even if it is already lazily loaded.So, you probably shouldn't use subpackages with this lazy feature.\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "/home/omega/.local/lib/python3.10/site-packages/lazy_loader/__init__.py:185: RuntimeWarning: subpackages can technically be lazily loaded, but it causes the package to be eagerly loaded even if it is already lazily loaded.So, you probably shouldn't use subpackages with this lazy feature.\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive # To Get an Access to Google Drive\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "import random\n",
    "import librosa\n",
    "import librosa.display\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import warnings\n",
    "import psutil\n",
    "import sys\n",
    "import soundfile as sf\n",
    "\n",
    "#!rm -r newClips mixAudio spectrogram mask temp vector csv # to reset the folders\n",
    "warnings.filterwarnings(\"ignore\", message=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘newClips’: File exists\n",
      "mkdir: cannot create directory ‘mixAudio’: File exists\n",
      "mkdir: cannot create directory ‘spectrogram’: File exists\n",
      "mkdir: cannot create directory ‘mask’: File exists\n",
      "mkdir: cannot create directory ‘temp’: File exists\n",
      "mkdir: cannot create directory ‘vector’: File exists\n",
      "mkdir: cannot create directory ‘csv’: File exists\n"
     ]
    }
   ],
   "source": [
    "# ----- main -------------------------------------------------------------------------\n",
    "\n",
    "# --> selcting path\n",
    "!mkdir newClips mixAudio spectrogram mask temp vector csv\n",
    "def path(folder):\n",
    "\n",
    "    directory = {\n",
    "        \"clips\": \"clips/\",\n",
    "        \"newClips\": \"newClips/\",\n",
    "        \"mixAudio\": \"mixAudio/\",\n",
    "        \"spectrogram\": \"spectrogram/\",\n",
    "        \"mask\": \"mask/\",\n",
    "        \"temp\": \"temp/\",\n",
    "        \"vector\":\"vector/\",\n",
    "        \"csv\":\"csv/\"\n",
    "    }\n",
    "\n",
    "    return directory[folder]\n",
    "\n",
    "# --> Print summary of Hyperparameters\n",
    "def summary(num_of_samples, length, start_time, end_time, num_of_audios, num_combined_voices, num_lowest_length, num_highest_length):\n",
    "    print(f\"--> Number of samples : {num_of_samples}\")\n",
    "    print(f\"--> Number of newClips: {num_of_audios}\")\n",
    "    print(f\"--> Number of combined voices: {num_combined_voices}\")\n",
    "    print(f\"--> Clip length : {length}\")\n",
    "    print(f\"--> Clip Timing : [ {start_time / 1000} : {end_time / 1000} ] \")\n",
    "    print(f\"--> Voices Domain : [ {num_lowest_length / 1000} : {num_highest_length / 1000} ] \")\n",
    "\n",
    "# --> Load Files\n",
    "def load(path):\n",
    "    var = np.load(path)\n",
    "    return var\n",
    "\n",
    "# --> Save DataFrames\n",
    "def save_df(file, name):\n",
    "    newData_path = path('csv') + name\n",
    "    file.to_csv(f'{newData_path}.csv', index=False)  # Save as CSV file\n",
    "    \n",
    "# ----- Tools -------------------------------------------------------------------------\n",
    "\n",
    "# --> check a varible size in mb\n",
    "def tool_var_size(var):\n",
    "    size_in_bytes = sys.getsizeof(var)\n",
    "    size_in_mb = size_in_bytes / (1024 * 1024)\n",
    "    print(f\"The size is {size_in_mb:.2f} MB.\")\n",
    "\n",
    "# --> check RAM size\n",
    "def tool_ram_size():    \n",
    "    vm_stats = psutil.virtual_memory()\n",
    "    available_str = psutil._common.bytes2human(vm_stats.available)\n",
    "    \n",
    "    print(\"Available memory: {}\".format(available_str))\n",
    "    \n",
    "# --> Get ID number from a path\n",
    "def tool_file_id(file_path):\n",
    "    file_path = file_path.split('.')[0]\n",
    "    id_number = file_path.split('_')[-1]\n",
    "    return id_number\n",
    "    \n",
    "# ----- Audio -------------------------------------------------------------------------\n",
    "\n",
    "# --> play [audio_path]\n",
    "def audio_play_path(audio_path):\n",
    "    audio = AudioSegment.from_file(audio_path)\n",
    "    return audio\n",
    "\n",
    "# --> play [spectrogram]\n",
    "def audio_play_spec(spec, name='spec_to_audio', target_dbfs= -24):    \n",
    "    audio = librosa.istft(spec)\n",
    "  \n",
    "    newData_path = os.path.join('temp', f'{name}.wav')\n",
    "\n",
    "    sf.write(newData_path, audio, 22050) # to convert it to AudioSegment type\n",
    "    audio = AudioSegment.from_file(newData_path)\n",
    "    \n",
    "    current_dbfs = audio.dBFS\n",
    "    gain_needed = target_dbfs - current_dbfs\n",
    "    audio = audio + gain_needed\n",
    "    return audio\n",
    "\n",
    "# ----- Spectogram -------------------------------------------------------------------------\n",
    "\n",
    "# --> Create Spectrogram\n",
    "def spec_creation(audio_path, sr=22050):\n",
    "    y, sr = librosa.load(audio_path)\n",
    "    spectrogram = librosa.stft(y)\n",
    "    spectrogram = spec_normalization(spectrogram)\n",
    "    return spectrogram\n",
    "\n",
    "# --> Scale Factor Normalization \n",
    "def spec_normalization(spec):\n",
    "    spec_max = np.max(spec)\n",
    "    spec_min = np.min(spec)\n",
    "\n",
    "    scale_factor = max(abs(spec_max), abs(spec_min))\n",
    "\n",
    "    spec_norm = spec / scale_factor\n",
    "    normalized_spec = np.clip(spec_norm, -1.0, 1.0)\n",
    "    return(normalized_spec)\n",
    "\n",
    "# --> visualization  \n",
    "def spec_visualize(spec):\n",
    "    librosa.display.specshow((spec), sr=22050, x_axis='time', y_axis='log')\n",
    "\n",
    "# --> Applay mask on Spectrogram\n",
    "def spec_applay_mask(spec_path, mask_path):\n",
    "    \n",
    "    spec = np.load(spec_path) if isinstance(spec_path, str) else spec_path\n",
    "    mask = np.load(mask_path) if isinstance(mask_path, str) else mask_path        \n",
    "    \n",
    "    masked_spectrogram = spec * mask   \n",
    "    return masked_spectrogram\n",
    "\n",
    "# --> save audio as spectrgram and return the path\n",
    "def spec_save(audio_path):\n",
    "    newData_path = path('spectrogram') + 'spec_' + tool_file_id(audio_path)+ '.npy'\n",
    "    spec = spec_creation(audio_path)\n",
    "    \n",
    "    np.save(newData_path, spec)\n",
    "    return(newData_path)\n",
    "\n",
    "# ----- Mask -------------------------------------------------------------------------\n",
    "\n",
    "# --> create spectrogram binary mask\n",
    "def mask_creation(audio_path, percentile=97):\n",
    "    spec = spec_creation(audio_path)\n",
    "    mag = np.abs(spec)\n",
    "\n",
    "    threshold = np.percentile(mag, percentile)\n",
    "    mask = (mag > threshold)\n",
    "    \n",
    "    return mask.astype(int)\n",
    "\n",
    "# --> save audio as binary mask and return the path\n",
    "def mask_save(audio_path):\n",
    "    newData_path = path('mask') + 'mask_' + tool_file_id(audio_path)+ '.npy'\n",
    "    mask = mask_creation(audio_path)\n",
    "    \n",
    "    np.save(newData_path, mask)\n",
    "    return(newData_path)\n",
    "\n",
    "# --> Convert a many maskS to one vector \n",
    "def mask_vector(m1_path, m2_path, m3_path):\n",
    "    mask_1 = load(m1_path)\n",
    "    mask_2 = load(m2_path)\n",
    "    mask_3 = load(m3_path)\n",
    "    \n",
    "    masks = np.concatenate((mask_1, mask_2, mask_3), axis=1)\n",
    "    vector = np.reshape(masks, (-1,))\n",
    "    \n",
    "    return vector\n",
    "\n",
    "# --> save vector \n",
    "def mask_vector_save(m1_path, m2_path, m3_path):\n",
    "    mID_1 = tool_file_id(m1_path)\n",
    "    mID_2 = tool_file_id(m2_path)\n",
    "    mID_3 = tool_file_id(m3_path)\n",
    "    \n",
    "    newData_path = path('vector') + f'vector_{mID_1}_{mID_2}_{mID_3}.npy'\n",
    "    vector = mask_vector(m1_path, m2_path, m3_path)\n",
    "    \n",
    "    np.save(newData_path, vector)\n",
    "    return newData_path\n",
    "\n",
    "# convert vector to masks\n",
    "def mask_vector_resahpe(vector, num_frequency_bins = 1025):\n",
    "    masks = vector.reshape(num_frequency_bins,-1)\n",
    "    coulmns = int(masks.shape[1]/num_combined_voices)\n",
    "\n",
    "    mask_1 = masks[:, :coulmns]\n",
    "    mask_2 = masks[:, coulmns:coulmns*2]\n",
    "    mask_3 = masks[:, coulmns*2:]\n",
    "    \n",
    "    return mask_1, mask_2, mask_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Number of samples : 10\n",
      "--> Number of newClips: 30\n",
      "--> Number of combined voices: 3\n",
      "--> Clip length : 2\n",
      "--> Clip Timing : [ 1.5 : 3.5 ] \n",
      "--> Voices Domain : [ 3.5 : 6.0 ] \n"
     ]
    }
   ],
   "source": [
    "# FINAL Numbers of samples in the DataFrame\n",
    "num_of_samples= 10\n",
    "\n",
    "# The clip length in seconds\n",
    "length = 2\n",
    "\n",
    "# Define the clip from audio with a fixed length (end_time - start_time) in milliseconds \n",
    "start_time = 1500\n",
    "end_time = start_time + (length * 1000) #FIXED\n",
    "\n",
    "# Total number of new fixed length audios\n",
    "num_of_audios = num_of_samples * 3 # FIXED\n",
    "\n",
    "# Number of merging voices fixed for now\n",
    "num_combined_voices = 3 # FIXED\n",
    "\n",
    "# Define the domain to pick voices\n",
    "num_lowest_length = end_time #FIXED (end_time)\n",
    "num_highest_length = 6000\n",
    "\n",
    "# Summary \n",
    "summary(num_of_samples, length, start_time, end_time, num_of_audios, num_combined_voices, num_lowest_length, num_highest_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_files = os.listdir('clips')\n",
    "data = pd.read_csv('validated.tsv', sep='\\t')\n",
    "audio_time = pd.read_table('times.txt', header=None, names=['Time']).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data = audio_time.apply(lambda x: x.split('/')[-1])\n",
    "split_data = split_data.apply(lambda x: x.split('='))\n",
    "\n",
    "file_names = split_data.apply(lambda x: x[0].strip()).str[:-1]\n",
    "time = split_data.apply(lambda x: x[1].strip())\n",
    "\n",
    "mask = file_names.isin(data.path) \n",
    "mask = mask[mask == True]\n",
    "\n",
    "file_names = file_names.where(mask).dropna()\n",
    "time = time.where(mask).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split time.txt into file Name and time\n",
    "split_data = audio_time.apply(lambda x: x.split('/')[-1])\n",
    "split_data = split_data.apply(lambda x: x.split('='))\n",
    "\n",
    "file_names = split_data.apply(lambda x: x[0].strip()).str[:-1]\n",
    "time = split_data.apply(lambda x: x[1].strip())\n",
    "\n",
    "mask = file_names.isin(data.path) \n",
    "mask = mask[mask == True]\n",
    "\n",
    "file_names = file_names.where(mask).dropna()\n",
    "time = time.where(mask).dropna()\n",
    "\n",
    "df_time = pd.DataFrame({'path':file_names, 'time':time}) \n",
    "df_time = df_time.sort_values(by='time', key=lambda x: x.astype(int), ignore_index=True)\n",
    "\n",
    "df_time = df_time.where((df_time['time'].astype(int) > num_lowest_length) & (df_time['time'].astype(int) < num_highest_length)).dropna()\n",
    "df_time = df_time.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = data.drop(['client_id', 'up_votes','down_votes','variant','segment', 'accents', 'locale', 'age', 'gender','sentence'], axis=1)\n",
    "csv = csv.merge(df_time, on='path', how='right')\n",
    "csv = csv.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2252/2252 [00:06<00:00, 335.73it/s]\n"
     ]
    }
   ],
   "source": [
    "csv['exist'] = False\n",
    "\n",
    "for i in tqdm(range(len(csv))):\n",
    "    newData_path = path('clips') + csv['path'][i]\n",
    "    if os.path.exists(newData_path):\n",
    "        csv.loc[i, 'exist'] = True\n",
    "\n",
    "csv = csv[csv['exist'] == True]\n",
    "csv = csv.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:10<00:00,  2.93it/s]\n"
     ]
    }
   ],
   "source": [
    "csv['newClip'] = ''\n",
    "for i in tqdm(range(0,num_of_audios)): \n",
    "    newData_path = path('newClips') + csv['path'][i]\n",
    "    \n",
    "    clip = AudioSegment.from_file(path('clips') + csv['path'][i])\n",
    "    clip = clip[start_time:end_time]\n",
    "\n",
    "    clip.export(newData_path, format='mp3')\n",
    "    csv['newClip'][i] = newData_path\n",
    "    \n",
    "csv = csv[:num_of_audios]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:08<00:00,  1.21it/s]\n"
     ]
    }
   ],
   "source": [
    "df_audio = pd.DataFrame({'mixAudio': [], 'x1': [], 'x2': [], 'x3': []})\n",
    "\n",
    "index = 0\n",
    "\n",
    "for i in tqdm(range(0,num_of_samples)): \n",
    "    newData_path = path('mixAudio') + 'mixAudio_' + str(i) + '.mp3'\n",
    "    mix = AudioSegment.from_file(csv['newClip'][index])\n",
    "    \n",
    "    for j in range(1,num_combined_voices): \n",
    "        Speaker_voice = AudioSegment.from_file(csv['newClip'][index+j])\n",
    "        mix = mix.overlay(Speaker_voice)\n",
    "    \n",
    "    mix.export(newData_path, format='mp3')    \n",
    "    df_audio = df_audio.append({'mixAudio': newData_path,'x1':csv['newClip'][index], 'x2':csv['newClip'][index+1], 'x3':csv['newClip'][index+2]}, ignore_index=True)\n",
    "    index = index + num_combined_voices # Skip merge audio and go for next\n",
    "save_df(df_audio, 'audio_path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.09it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 13.42it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 11.67it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 11.70it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 24.61it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "df = pd.DataFrame({'spectrogram': [], 'mask_1': [], 'mask_2': [], 'mask_3': [], 'vector': []})\n",
    "\n",
    "df['spectrogram'] = df_audio['mixAudio'].progress_apply(lambda x: spec_save(x))\n",
    "\n",
    "df['mask_1'] = df_audio['x1'].progress_apply(lambda x: mask_save(x))\n",
    "df['mask_2'] = df_audio['x2'].progress_apply(lambda x: mask_save(x))\n",
    "df['mask_3'] = df_audio['x3'].progress_apply(lambda x: mask_save(x))\n",
    "\n",
    "df['vector'] = df[['mask_1', 'mask_2', 'mask_3']].progress_apply(lambda row: mask_vector_save(row['mask_1'], row['mask_2'], row['mask_3']), axis=1)\n",
    "save_df(df, 'Final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used for reshape vectore back to Masks \n",
    "num_frequency_bins = load(df['mask_1'][0]).shape[0]\n",
    "print( '' if num_frequency_bins == 1025 else f'!! Need to change num_frequency_bins to {num_frequency_bins}', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spectrogram</th>\n",
       "      <th>mask_1</th>\n",
       "      <th>mask_2</th>\n",
       "      <th>mask_3</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spectrogram/spec_0.npy</td>\n",
       "      <td>mask/mask_37870464.npy</td>\n",
       "      <td>mask/mask_37532523.npy</td>\n",
       "      <td>mask/mask_37300591.npy</td>\n",
       "      <td>vector/vector_37870464_37532523_37300591.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spectrogram/spec_1.npy</td>\n",
       "      <td>mask/mask_37457241.npy</td>\n",
       "      <td>mask/mask_37701314.npy</td>\n",
       "      <td>mask/mask_38011105.npy</td>\n",
       "      <td>vector/vector_37457241_37701314_38011105.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spectrogram/spec_2.npy</td>\n",
       "      <td>mask/mask_37531336.npy</td>\n",
       "      <td>mask/mask_37539141.npy</td>\n",
       "      <td>mask/mask_37396167.npy</td>\n",
       "      <td>vector/vector_37531336_37539141_37396167.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spectrogram/spec_3.npy</td>\n",
       "      <td>mask/mask_37306217.npy</td>\n",
       "      <td>mask/mask_37679894.npy</td>\n",
       "      <td>mask/mask_37935235.npy</td>\n",
       "      <td>vector/vector_37306217_37679894_37935235.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spectrogram/spec_4.npy</td>\n",
       "      <td>mask/mask_37780661.npy</td>\n",
       "      <td>mask/mask_37289274.npy</td>\n",
       "      <td>mask/mask_37937553.npy</td>\n",
       "      <td>vector/vector_37780661_37289274_37937553.npy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              spectrogram                  mask_1                  mask_2  \\\n",
       "0  spectrogram/spec_0.npy  mask/mask_37870464.npy  mask/mask_37532523.npy   \n",
       "1  spectrogram/spec_1.npy  mask/mask_37457241.npy  mask/mask_37701314.npy   \n",
       "2  spectrogram/spec_2.npy  mask/mask_37531336.npy  mask/mask_37539141.npy   \n",
       "3  spectrogram/spec_3.npy  mask/mask_37306217.npy  mask/mask_37679894.npy   \n",
       "4  spectrogram/spec_4.npy  mask/mask_37780661.npy  mask/mask_37289274.npy   \n",
       "\n",
       "                   mask_3                                        vector  \n",
       "0  mask/mask_37300591.npy  vector/vector_37870464_37532523_37300591.npy  \n",
       "1  mask/mask_38011105.npy  vector/vector_37457241_37701314_38011105.npy  \n",
       "2  mask/mask_37396167.npy  vector/vector_37531336_37539141_37396167.npy  \n",
       "3  mask/mask_37935235.npy  vector/vector_37306217_37679894_37935235.npy  \n",
       "4  mask/mask_37937553.npy  vector/vector_37780661_37289274_37937553.npy  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('csv/Final.csv')\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
